# Task_08_Bias_Detection

## 1. Overview

This repository implements Task 08: Bias Detection in LLM Data Narratives, using the 2025 Syracuse women’s lacrosse season as the case study. We test framing effects, demographic/role bias, and confirmation bias across multiple LLMs.

---

## 2. Repository Structure

- `prompts/` – Prompt templates and JSONL prompt definitions.
- `results/raw/` – Raw JSONL responses from LLMs (may be excluded from Git).  
- `results/processed/` – Processed CSVs such as `llm_responses.csv`, `claim_validation_flags.csv`.
- `analysis/` – Statistical tests, visualizations, and summary tables.
- `experiment_design.py` – Generates all prompt variants.
- `run_experiment.py` – Sends prompts to LLMs and logs responses.
- `analyze_bias.py` – Processes responses into structured datasets.
- `validate_claims.py` – Checks claims against ground truth stats.
- `fabrication_rate.py` – Computes fabrication/overclaim rates.
- `analysis_visualizations.py` – Generates core plots.
- `analysis_save_stats.py` – Saves chi-square and z-test outputs to `analysis/stat_tests.*`.
- `REPORT.md` – Final bias detection report.
- `requirements.txt` – Python package dependencies.

---

## 3. Setup

- pip install -r requirements.txt

---
## 4. Running the Pipeline

**4.1 Generate prompts**
- python experiment_design.py

**4.2 Collect LLM responses**
- python run_experiment.py

**4.3 Process and validate outputs**
- **Convert JSONL → clean CSV:**
    - python analyze_bias.py
- **Validate each model claim against true stats:**
    - python validate_claims.py
- **Files produced:**
    - results/processed/llm_responses.csv- 
    - results/processed/claim_validation_flags.csv

**4.4 Quantitative analysis**
- **Compute fabrication & overclaim rates:**
    - python fabrication_rate.py
- **Run chi-square tests, z-tests, effect sizes:**
    - python analysis_save_stats.py
- **Generate visualizations (bar charts & heatmaps):**
    - python analysis_visualizations.py
  
**4.5 View results in:**
- **Processed CSV files**
    - results/processed/
- **Statistical tests + visualizations:**
    - analysis/ 

---

## 5. Reproducibility
This project is fully reproducible because:
- Model versions are stored in every JSONL record.
- Prompt templates are fixed and auto-generated by experiment_design.py.
- Randomness only comes from temperature-based sampling.
- All numeric validation steps (validate_claims.py) are deterministic.
- All analysis scripts save outputs with consistent file names.

To fully rerun the study:
- Regenerate prompts
- Re-query LLMs
- Re-run all analysis scripts
- Prompt templates and parameters are fixed in experiment_design.py.
- Randomness comes from LLM sampling, reruns may vary slightly.

Processing and validation steps (analyze_bias.py, validate_claims.py) are deterministic.
